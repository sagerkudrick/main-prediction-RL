<input type="file" id="imageInput" accept="image/*" />
<img id="preview" width="224" height="224" style="display:none;" />

<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>

<script>
async function loadImageTensor(file, width=224, height=224) {
    return new Promise((resolve) => {
        const img = document.getElementById("preview");
        img.src = URL.createObjectURL(file);
        img.onload = () => {
            const canvas = document.createElement("canvas");
            canvas.width = width;
            canvas.height = height;
            const ctx = canvas.getContext("2d");
            ctx.drawImage(img, 0, 0, width, height);
            const imageData = ctx.getImageData(0, 0, width, height).data;

            const tensorData = new Float32Array(3 * width * height); // CxHxW
            for (let y=0; y<height; y++) {
                for (let x=0; x<width; x++) {
                    const i = (y*width + x)*4;
                    const alpha = imageData[i+3]/255;
                    for (let c=0; c<3; c++) {
                        // Blend with white background, normalize [-1,1] like Python
                        const val = (imageData[i+c]*alpha + 255*(1-alpha))/255;
                        tensorData[c*width*height + y*width + x] = (val - 0.5)/0.5;
                    }
                }
            }

            // Print a few debug values
            console.log("‚úÖ Tensor slice [C0 first row]:", tensorData.slice(0, 10));
            resolve(tensorData);
        };
    });
}

async function debugONNXModel(session) {
    console.log("======================================");
    console.log("üß† ONNX MODEL SUPER DEBUG INSPECTOR");
    console.log("======================================");

    // Check provider
    console.log("‚≠ê Execution Providers:", session.executionProvider || "Unknown");

    //--------------------------
    // 0. Metadata safe loading
    //--------------------------
    let metadata = null;

    try {
        metadata = await session.getModelMetadata();
    } catch (err) {
        console.warn("‚ö†Ô∏è Could NOT load metadata (usually WebGL backend crash)", err);
    }

    //--------------------------
    // 1. Model metadata
    //--------------------------
    console.log("=== Metadata ===");
    if (metadata) {
        console.log("¬∑ producerName:", metadata.producerName);
        console.log("¬∑ graphName:", metadata.graphName);
        console.log("¬∑ domain:", metadata.domain);
        console.log("¬∑ description:", metadata.description);
        console.log("¬∑ version:", metadata.version);
    } else {
        console.log("‚ùå Metadata unavailable");
    }

    //--------------------------
    // 2. Inputs
    //--------------------------
    console.log("=== Inputs ===");
    const inputNames = session.inputNames || [];
    const inputMeta = session.inputMetadata || {};

    if (inputNames.length === 0) {
        console.log("‚ùå No input names returned by session");
    }

    inputNames.forEach(name => {
        const meta = inputMeta[name];

        console.log(`üü¶ Input: ${name}`);
        if (!meta) {
            console.log(`   ‚ùå No metadata (WebGL may have failed to initialize this tensor)`);
            return;
        }

        console.log("   ‚Ä¢ Type:", meta.type);
        console.log("   ‚Ä¢ Dimensions:", meta.dimensions);
    });

    //--------------------------
    // 3. Outputs
    //--------------------------
    console.log("=== Outputs ===");
    const outputNames = session.outputNames || [];
    const outputMeta = session.outputMetadata || {};

    if (outputNames.length === 0) {
        console.log("‚ùå No output names returned by session");
    }

    outputNames.forEach(name => {
        const meta = outputMeta[name];

        console.log(`üü© Output: ${name}`);
        if (!meta) {
            console.log(`   ‚ùå No metadata (WebGL may have failed to initialize this tensor)`);
            return;
        }

        console.log("   ‚Ä¢ Type:", meta.type);
        console.log("   ‚Ä¢ Dimensions:", meta.dimensions);
    });

    //--------------------------
    // 4. WebGL kernel availability
    //--------------------------
    console.log("=== WebGL Kernel Support (available ops) ===");
    try {
        console.log(ort.env.webgl.ops);
    } catch {
        console.log("‚ùå WebGL ops not accessible");
    }

    //--------------------------
    // 5. Provider + env debug
    //--------------------------
    console.log("=== ONNX Runtime Environment Info ===");
    console.log("‚Ä¢ WebGL Enabled:", ort.env.webgl?.enabled);
    console.log("‚Ä¢ WebGL Version:", ort.env.webgl?.contextAttributes);
    console.log("‚Ä¢ Log Level:", ort.env.logLevel);

    console.log("======================================");
    console.log("üîç Debug complete.");
    console.log("======================================");
}


async function runInferenceDebug(session, file) {
    const inputName = session.inputNames[0];
    const tensorData = await loadImageTensor(file);

    const feeds = {
        [inputName]: new ort.Tensor('float32', tensorData, [1, 3, 224, 224])
    };

    // Print input tensor stats
    console.log("=== Input Tensor ===");
    console.log("Shape:", feeds[inputName].dims);
    console.log("Type:", feeds[inputName].type);
    console.log("First 10 values:", feeds[inputName].data.slice(0, 10));

    // Run inference on CPU first
    console.log("‚è≥ Running inference on CPU...");
    const sessionCPU = await ort.InferenceSession.create('static/models/model.onnx', {executionProviders:['cpu']});
    const outputCPU = await sessionCPU.run(feeds);
    const outputName = sessionCPU.outputNames[0];
    console.log("‚úÖ CPU Output:", outputCPU[outputName].data.slice(0,10));

    // Run inference on WebGL
    console.log("‚è≥ Running inference on WebGL...");
    const outputWebGL = await session.run(feeds);
    console.log("‚úÖ WebGL Output:", outputWebGL[outputName].data.slice(0,10));

    // Sanity check for extreme values
    const check = outputWebGL[outputName].data;
    const minVal = Math.min(...check);
    const maxVal = Math.max(...check);
    console.log(`Output range: min=${minVal}, max=${maxVal}`);
}

document.getElementById("imageInput").addEventListener("change", async (e) => {
    if (e.target.files.length === 0) return;

    const modelPath = "static/models/model.onnx";

    try {
        // 1. Load session first (CPU to avoid WebGL crashes during inspection)
        const sessionCPU = await ort.InferenceSession.create(modelPath, {
            executionProviders: ["cpu"]
        });

        // 2. Debug model using the valid session
        await debugONNXModel(sessionCPU);

        // 3. Now load WebGL session
        const sessionWebGL = await ort.InferenceSession.create(modelPath, {
            executionProviders: ["webgl"]
        });

        // 4. Run inference
        await runInferenceDebug(sessionWebGL, e.target.files[0]);

    } catch (err) {
        console.error("‚ùå Fatal error:", err);
        alert("Error running inference. Check DevTools console.");
    }
});

</script>
